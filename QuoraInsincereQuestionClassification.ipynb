{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n#df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/quora-insincere-questions-classification/train.csv\")\ndf_test = pd.read_csv(\"../input/quora-insincere-questions-classification/test.csv\")\n\nprint(\"Training Data Shape\", df_train.shape)\nprint(\"Testing Data Shape\", df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting Training and Val\ndf_train, df_val = train_test_split(df_train, test_size = 0.1, random_state = 2020)\n\n#Paramaeters\nembed_size = 300\nmax_features = 50000\nmax_length = 100\n\n#Missing Values\n\nx_train = df_train['question_text'].fillna(\"na_vals\").values\nx_val = df_val['question_text'].fillna(\"na_vals\").values\nx_test = df_test['question_text'].fillna(\"na_vals\").values\n\ny_train = df_train['target']\ny_val = df_val['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Preprocessing Text\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(x_train)\nsequences_train = tokenizer.texts_to_sequences(list(x_train))\nsequences_val = tokenizer.texts_to_sequences(x_val)\nsequences_test = tokenizer.texts_to_sequences(x_test)\n\n#Padding\npadded_train = pad_sequences(sequences_train, maxlen = max_length)\npadded_val = pad_sequences(sequences_val, maxlen = max_length)\npadded_test = pad_sequences(sequences_test, maxlen = max_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# No external Embeddings - such as Word2Vec or Glove, building on just the vocabulary from training dataset\nimport keras\n\nmodel = keras.Sequential([\n        keras.layers.Embedding(max_features, embed_size),\n        keras.layers.GlobalAveragePooling1D(),\n        keras.layers.Dense(32, activation = 'relu'),\n        keras.layers.Dense(8, activation = 'relu'),\n        keras.layers.Dense(1, activation = 'sigmoid')\n    \n])\nmodel.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10\nhistory = model.fit(padded_train,y_train, batch_size = 512, epochs = num_epochs, validation_data = (padded_val,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n  \nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"loss\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Bidirection GRU Model\nfrom keras.layers import CuDNNGRU\n\nmodelGRU = keras.Sequential([\n        keras.layers.Embedding(max_features, embed_size),\n        keras.layers.Bidirectional(CuDNNGRU(64,return_sequences = True)),\n        keras.layers.GlobalAveragePooling1D(),\n        keras.layers.Dense(16, activation = 'relu'),\n        keras.layers.Dense(8, activation = 'relu'),\n        keras.layers.Dense(1, activation = 'sigmoid')\n    \n])\nmodelGRU.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nprint(model.summary())"},{"metadata":{},"cell_type":"markdown","source":"Embeddings Available\n* GoogleNews-vectors-negative300 - https://code.google.com/archive/p/word2vec/\n* glove.840B.300d - https://nlp.stanford.edu/projects/glove/\n* paragram_300_sl999 - https://cogcomp.org/page/resource_view/106\n* wiki-news-300d-1M - https://fasttext.cc/docs/en/english-vectors.html"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Using Pre-Trained embeddings\n#!ls ../input/quora-insincere-questions-classification/embeddings/\nimport zipfile\n#from os import path, getcwd, chdir\n\n#path = f\"{getcwd()}/../input/quora-insincere-questions-classification/embeddings.zip\"\n\nzip_ref = zipfile.ZipFile(\"../input/quora-insincere-questions-classification/embeddings.zip\", 'r')\nzip_ref.extractall(\".\")\nzip_ref.close()\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"embeddings\"]).decode(\"utf8\"))"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Not using Standard Preprocessing but custom preprocessing and building vocab from the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\ntqdm.pandas()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}